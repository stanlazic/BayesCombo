---
title: "BayesCombo: A Quick Guide"
author: "Bruno Contrino & Stanley E. Lazic"
date: "4 August 2016"
output: 
  rmarkdown::html_vignette:
    toc: true
    number_sections: FALSE
vignette: >
  %\VignetteIndexEntry{BayesCombo}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo = FALSE, warning= FALSE,message=FALSE}
library(BayesCombo)
```

# Introduction 

Multiple experiments are often used to test hypotheses, evaluate theories, or draw conclusions. Both the types of experiments and the measured outcomes can be diverse, and conclusions are usually based on the number of significant p-values across experiments. P-values, however, are a poor way of testing hypotheses, and since statistical power is often low, "conflicting results" are common. In addition, the diversity of methods makes it hard to formally combine results with a standard meta-analysis. Informal methods of evaluating a series of experiments makes inefficient use of the data and can lead to incorrect conclusions and poor decisions. Here we show how to combine evidence &#8211; captured by Bayes factors &#8211; across diverse experiments based on a method developed by Kuiper et al. [1]. 




# Usage 

The required inputs to calculate Bayes factors are coefficients and their standard errors obtained from the output of `lm()` and `glm()` functions (e.g. from ANOVAs, t-tests, or regressions with Gaussian, Poisson, or Binomial outcomes). It's up to the user to ensure that the data being combined are testing the same overall hypothesis or theory. In addition, the direction of the effects should be aligned; for example, if a positive effect size in one study is interpreted as supporting a theory, but a negative effect size in another study also supports the theory, then the negative effect should be multiplied by -1 to change its direction.

The Bayes factors are not used directly but only as an intermediate step to calculate the probability that the true effect size is less than zero, greater than zero, or exactly zero. These three probabilities are called the posterior model probabilities (PMPs), where a model corresponds to one of the three effects.


## Calculate posterior model probabilities (PMPs)

`calculate.PMP()` is the main analysis function and only requires the effect sizes (`beta`) and their standard errors (`se.beta`) as input. The default prior mean (`beta0 = 0`) is suitable for most analyses, as is the equal prior model probabilities (`pi0 =c(1/3, 1/3, 1/3)`) for each model. In the example below, assume we have four clinical trials where positive effect sizes indicate a beneficial effect of a treatment.

```{r calculatePMP}
pmp <- calculate.PMP(beta = c(2.3, 1.2, 0.2, 0.44),
	                 se.beta = c(1.03, 0.75, 0.16, 0.28))
```


Plotting a `BFcombo` object generates a graph resembling a forest plot, with the observed effect sizes and their 99% CI (black) and the prior effect sizes (usually zero) and their variances (red). All four studies have positive effect sizes but only the first study is significant at the usual 0.05 level.


```{r plotBF}
plot(pmp)
```

A summary of the results shows how the support for the three hypothesis changes as each study is added. For example, in the output below we see that when only the first study is included (first column) the probability that the effect size is greater than zero (`H:>`) is about 85%. As more studies are included, the probability increases to 98%, and the null has only 1.8% support.


```{r summaryPMP}
summary(pmp)$PMP
```

It is easier to see how these probabilities change as studies are added with a graph.


```{r PMPplot, fig.height=4, fig.width=6}
par(las=1)
PMP.plot(pmp)
```



## Bayesian Safety (BS) factor

When the posterior probability for a non-null hypothesis is large, it may be of interest to calculate the prior for the null that gives a just  significant result. Here 'significant' is a threshold that the posterior must exceed. For example, if a series of experiments on homeopathy gives a posterior probability of 0.98 in favour homeopathy's effectiveness, we can calculate the strength of the prior needed to make the posterior just pass the 0.98 threshold. If the BS factor is very large (sceptical prior), then we may be more inclined to believe the results because they were sufficient to shift a strong prior belief in no effect. If the data can only overcome a weak prior, then the results may be unconvincing, despite having a large posterior probability. We can ask ourselves if our prior is greater or less than the BS factor, and judge the results accordingly.

given a threshold, how much weight you can give a certain hypothesis in the prior model probabilities. This can aid making a conclusion on the outcome of the standard analysis. 


**n** 

This is the number of steps from 0.33333 to 0.99999 which the prior model probabilities will take. The default is 100. 

**threshold** 

This is a value between 0 and 1 which will be used to set the boundary point at which the PMP value is less than as the prior model probabilities change. The default is 0.95. 

**hypothesis**

This has two properties depending on the value of the `reverse` parameter.

When reverse is `TRUE` the value of hypothesis refers to the hypothesis which will be tested against the null. That is to say the given this hypothesis one can give the null hypothesis a certain amount of weight until the result of the analysis changes drastically.


When reverse is `FALSE` the value of hypothesis refers to the hypothesis which will be added weight instead of the null hypothesis. The null is then used to set the boundary. 
The default value for hypothesis is 1. It can take 2 as another input. 


**reverse**

See hypothesis parameter for a detailed description. 

Default value of reverse is `TRUE`.



#### Example

```{r BSfactor}
bs <- BSfactor(pmp, reverse = TRUE , n = 12 )

summary(bs)
```


The output of summary consists of a list with the following sections:

**PMP**

Gives the first and the last row of the posterior model probabilities, these correspond to the prior model probabilities in the priorMP section.

**priorMP**

Gives the first and the last row of the prior model probabilities, these correspond to the posterior model probabilities in the PMP section.

**boundary**

Gives the boundary value when the PMP value reaches the threshold.

**threshold**

The threshold used to give the boundary.

**hypothesis**





#### Plot For "BSfactor" object

Plot when used on a object of class "BSfactor" will give a visualisation of the change in posterior model probability values for each hypothesis as the prior model probabilities are changed. 


```{r plotBS, fig.height=4,fig.width=8}
plot(bs)
```




# References 

[1] Kuiper RM, Buskens V, Raub W, Hoijtink H (2012). Combining statistical evidence from several studies: A method using Bayesian updating and an example from research on trust problems in social and economic exchange. __Sociological Methods and Research__ 42(1) 60-81.
